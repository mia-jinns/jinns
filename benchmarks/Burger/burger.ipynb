{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Burger equation\n",
    "\n",
    "Comparison of DeepXDE and Jinns performance on the Burger equation \n",
    "\n",
    "\n",
    "## DeepXDE\n",
    "Example taken from : https://deepxde.readthedocs.io/en/latest/demos/pinn_forward/burgers.html\n",
    "\n",
    "We use the JAX backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: jax\n",
      "Other supported backends: tensorflow.compat.v1, tensorflow, pytorch, paddle.\n",
      "paddle supports more examples now and is recommended.\n",
      "Enable just-in-time compilation with XLA.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 8192 points required, but 8256 points sampled.\n",
      "Compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 17:01:55.289893: W external/xla/xla/service/gpu/nvptx_compiler.cc:893] The NVIDIA driver's CUDA version is 12.2 which is older than the PTX compiler version 12.3.107. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'compile' took 1.380288 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Traced<ShapedArray(float32[16450,1])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Traced<ShapedArray(float32[16450,1])>with<DynamicJaxprTrace(level=1/0)>\n",
      "Step      Train loss                        Test loss                         Test metric\n",
      "0         [1.06e-02, 7.72e-02, 3.40e-01]    [1.06e-02, 7.72e-02, 3.40e-01]    []  \n",
      "1000      [5.66e-02, 7.28e-04, 3.03e-02]    [5.66e-02, 7.28e-04, 3.03e-02]    []  \n",
      "2000      [7.96e-02, 9.64e-04, 2.39e-01]    [7.96e-02, 9.64e-04, 2.39e-01]    []  \n",
      "3000      [7.09e-04, 2.20e-05, 8.68e-04]    [7.09e-04, 2.20e-05, 8.68e-04]    []  \n",
      "4000      [5.25e-02, 9.19e-03, 8.46e-03]    [5.25e-02, 9.19e-03, 8.46e-03]    []  \n",
      "5000      [5.67e-04, 5.02e-06, 1.63e-03]    [5.67e-04, 5.02e-06, 1.63e-03]    []  \n",
      "6000      [5.43e-04, 5.16e-06, 1.25e-03]    [5.43e-04, 5.16e-06, 1.25e-03]    []  \n",
      "7000      [1.98e-03, 2.09e-04, 1.16e-03]    [1.98e-03, 2.09e-04, 1.16e-03]    []  \n",
      "8000      [4.17e-04, 2.67e-05, 4.33e-04]    [4.17e-04, 2.67e-05, 4.33e-04]    []  \n",
      "9000      [3.04e-03, 2.68e-06, 8.11e-03]    [3.04e-03, 2.68e-06, 8.11e-03]    []  \n",
      "10000     [4.25e-02, 2.83e-03, 7.60e-02]    [4.25e-02, 2.83e-03, 7.60e-02]    []  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Backend supported: tensorflow.compat.v1, tensorflow, pytorch, paddle\"\"\"\n",
    "import os\n",
    "os.environ[\"DDE_BACKEND\"]=\"jax\"\n",
    "import deepxde as dde\n",
    "import numpy as np\n",
    "\n",
    "# Determinism may reduce performance in DeepXDE (see doc) but needs to\n",
    "# be set for a fair comparison with Jinns\n",
    "# https://deepxde.readthedocs.io/en/stable/modules/deepxde.html#deepxde.config.set_random_seed\n",
    "dde.config.set_random_seed(seed)\n",
    "\n",
    "\n",
    "def gen_testdata():\n",
    "    data = np.load(\"../dataset/Burgers.npz\")\n",
    "    t, x, exact = data[\"t\"], data[\"x\"], data[\"usol\"].T\n",
    "    xx, tt = np.meshgrid(x, t)\n",
    "    X = np.vstack((np.ravel(xx), np.ravel(tt))).T\n",
    "    y = exact.flatten()[:, None]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def pde(x, y):\n",
    "    y_val, y_fn = y\n",
    "    print(y_val)\n",
    "    dy_x, _ = dde.grad.jacobian(y, x, i=0, j=0)\n",
    "    dy_t, _ = dde.grad.jacobian(y, x, i=0, j=1)\n",
    "    dy_xx, _ = dde.grad.hessian(y, x, i=0, j=0)\n",
    "    return dy_t + y_val * dy_x - 0.01 / np.pi * dy_xx\n",
    "\n",
    "\n",
    "geom = dde.geometry.Interval(-1, 1)\n",
    "timedomain = dde.geometry.TimeDomain(0, 0.99)\n",
    "geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
    "\n",
    "bc = dde.icbc.DirichletBC(geomtime, lambda x: 0, lambda _, on_boundary: on_boundary)\n",
    "ic = dde.icbc.IC(\n",
    "    geomtime, lambda x: -np.sin(np.pi * x[:, 0:1]), lambda _, on_initial: on_initial\n",
    ")\n",
    "\n",
    "data = dde.data.TimePDE(\n",
    "    geomtime, pde, [bc, ic], num_domain=8192, num_boundary=2048, num_initial=2048, train_distribution=\"uniform\"\n",
    ")\n",
    "net = dde.nn.FNN([2] + [100] * 5 + [1], \"tanh\", \"Glorot normal\")\n",
    "model = dde.Model(data, net)\n",
    "\n",
    "model.compile(\"adam\", lr=1e-3)\n",
    "losshistory, train_state = model.train(iterations=20000)\n",
    "# Not sure how to do this in JAX\n",
    "# model.compile(\"L-BFGS\")\n",
    "# losshistory, train_state = model.train()\n",
    "dde.saveplot(losshistory, train_state, issave=True, isplot=True)\n",
    "\n",
    "X, y_true = gen_testdata()\n",
    "y_pred = model.predict(X)\n",
    "f = model.predict(X, operator=pde)\n",
    "print(\"Mean residual:\", np.mean(np.absolute(f)))\n",
    "print(\"L2 relative error:\", dde.metrics.l2_relative_error(y_true, y_pred))\n",
    "np.savetxt(\"test.dat\", np.hstack((X, y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2592+240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_points().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Jinns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import equinox as eqx\n",
    "import jinns\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, vmap, random\n",
    "import optax\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "key = random.PRNGKey(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqx_list = (\n",
    "    (eqx.nn.Linear, 2, 100),\n",
    "    (jax.nn.tanh,),\n",
    "    (eqx.nn.Linear, 100, 100),\n",
    "    (jax.nn.tanh,),\n",
    "    (eqx.nn.Linear, 100, 100),\n",
    "    (jax.nn.tanh,),\n",
    "    (eqx.nn.Linear, 100, 100),\n",
    "    (jax.nn.tanh,),\n",
    "    (eqx.nn.Linear, 100, 100),\n",
    "    (jax.nn.tanh,),\n",
    "    (eqx.nn.Linear, 100, 1)\n",
    ")\n",
    "key, subkey = random.split(key)\n",
    "u_pinn, init_nn_params_pinn = jinns.utils.create_PINN(subkey, eqx_list, \"nonstatio_PDE\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8192 # data.num_domain\n",
    "ni = 2048 # data.num_initial\n",
    "nb = 2048 # data.num_boundary\n",
    "dim = 1\n",
    "xmin = -1\n",
    "xmax = 1\n",
    "tmin = 0\n",
    "tmax = 1\n",
    "Tmax = 0.99\n",
    "method = \"grid\" # equals \"uniform\" in deepXDE, while \"uniform\" in jinns equals \"pseudo\" in deepXDE\n",
    "\n",
    "train_data = jinns.data.CubicMeshPDENonStatio(\n",
    "    key=subkey,\n",
    "    n=n,\n",
    "    nb=nb,\n",
    "    ni=ni,\n",
    "    dim=dim,\n",
    "    min_pts=(xmin,),\n",
    "    max_pts=(xmax,),\n",
    "    tmin=tmin,\n",
    "    tmax=tmax,\n",
    "    method=method,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Burger loss\n",
    "nu = 1 / (100 * jnp.pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init parameters for NN and equation\n",
    "init_params_pinn = jinns.parameters.Params(\n",
    "    nn_params=init_nn_params_pinn,\n",
    "    eq_params={\n",
    "        \"nu\":nu\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "be_loss = jinns.loss.BurgerEquation(Tmax=Tmax)\n",
    "\n",
    "def u0(x):\n",
    "    return -jnp.sin(jnp.pi * x)\n",
    "\n",
    "loss_weights = jinns.loss.LossWeightsPDENonStatio(\n",
    "    dyn_loss=1, initial_condition=1, boundary_loss=1\n",
    ")\n",
    "\n",
    "loss_pinn = jinns.loss.LossPDENonStatio(\n",
    "    u=u_pinn,\n",
    "    loss_weights=loss_weights,\n",
    "    dynamic_loss=be_loss,\n",
    "    omega_boundary_fun=lambda t_dx: 0,\n",
    "    omega_boundary_condition=\"dirichlet\",\n",
    "    initial_condition_fun=u0,\n",
    "    params=init_params_pinn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop in Jinns\n",
    "params_pinn = init_params_pinn\n",
    "tx = optax.adam(learning_rate=1e-3)\n",
    "n_iter = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_pinn, total_loss_list_pinn, loss_by_term_dict_pinn, _, _, _, _ , _, _ = jinns.solve(\n",
    "    init_params=params_pinn,\n",
    "    data=train_data,\n",
    "    optimizer=tx,\n",
    "    loss=loss_pinn,\n",
    "    n_iter=n_iter,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loss_name, loss_values in loss_by_term_dict_pinn.items():\n",
    "    plt.plot(jnp.log10(loss_values), label=loss_name)\n",
    "plt.plot(jnp.log10(total_loss_list_pinn), label=\"total loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 500\n",
    "val_xdata = jnp.linspace(xmin, xmax, nx)\n",
    "ntime = 500\n",
    "val_times = jnp.linspace(tmin, tmax, ntime)\n",
    "\n",
    "u_est_pinn = lambda t_x:u_pinn(t_x, params_pinn)\n",
    "# same subkey\n",
    "jinns.plot.plot1d_image(u_est_pinn, xdata=val_xdata, times=val_times, cmap=\"viridis\", colorbar=True, figsize=(5, 5), title=\"u(t, x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slices = [0, 0.2, 0.4, 0.75, 0.95, 1.]\n",
    "jinns.plot.plot1d_slice(u_est_pinn, xdata=val_xdata, time_slices=time_slices,  figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "diffs = []\n",
    "for i, ti in enumerate(time_slices):\n",
    "    val_ti = jnp.column_stack([val_xdata, jnp.repeat(ti, nx)])\n",
    "    val_ti_normalized = jnp.column_stack([jnp.repeat(ti, nx) / Tmax, val_xdata, ])\n",
    "    u_est_tfixed = vmap(u_est_pinn)#vmap(partial(u_est_pinn, t=ti * jnp.ones((1,)) / Tmax), 0, 0)\n",
    "    plt.plot(val_xdata, model.predict(x=val_ti), label=rf\"$DDE: t_i = {ti}$\", linestyle=\"--\", alpha=.7, color = cycle[i])\n",
    "    plt.plot(val_xdata, u_est_tfixed(val_ti_normalized), label=rf\"$Jinns:  t_i = {ti}$\", alpha=.7, color = cycle[i])\n",
    "    diffs.append(jnp.abs(u_est_tfixed(val_ti_normalized) - model.predict(x=val_ti)))\n",
    "\n",
    "    # plt.plot(val_xdata, u_est_tfixed(x=val_xdata[:, None]), label=rf\"$Jinns:  t_i = {ti}$\", alpha=.7, color = cycle[i])\n",
    "    # diffs.append(jnp.abs(u_est_tfixed(x=val_xdata[:, None]) - model.predict(x=val_ti)))\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "line_jinns = Line2D([0], [0], label='Jinns', color='black',linestyle=\"-\")\n",
    "line_dde = Line2D([0], [0], label='DeepXDE', color='black', linestyle=\"--\")\n",
    "plt.legend(handles=[line_jinns, line_dde])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dif, ti in zip(diffs, time_slices):\n",
    "    plt.plot(val_xdata, dif, label=rf\"x-differences at time $t_i={ti}$\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
