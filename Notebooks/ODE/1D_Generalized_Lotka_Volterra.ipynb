{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40925fec",
   "metadata": {},
   "source": [
    "# Generalized Lotka Volterra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b825efcb",
   "metadata": {},
   "source": [
    "We consider a Generalized Lotka Volterra system with $3$ populations\n",
    "$$\n",
    "\\frac{\\partial}{\\partial t}u_i(t) = r_iu_i(t) - \\sum_{j\\neq i}\\alpha_{ij}u_j(t)\n",
    "-\\alpha_{i,i}u_i(t) + c_iu_i(t) + \\sum_{j \\neq i} c_ju_j(t), i\\in\\{1, 2, 3\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f337b94d",
   "metadata": {},
   "source": [
    "More information on this ODE system can be found at [https://stefanoallesina.github.io/Sao_Paulo_School/intro.html#basic-formulation](https://stefanoallesina.github.io/Sao_Paulo_School/intro.html#basic-formulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf8bebc-b311-4eb4-ad63-11447f62b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddee93b7",
   "metadata": {},
   "source": [
    "Float64 and GPU settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cdc87e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os; os.environ[\"JAX_ENABLE_X64\"] = \"TRUE\" # comment/uncomment to  disable/enable float64 for JAX\n",
    "#import os; os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\" # If uncommented then GPU is disable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42b1b48",
   "metadata": {},
   "source": [
    "Import our package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbdd16f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 10:34:47.791352: W external/xla/xla/service/gpu/nvptx_compiler.cc:893] The NVIDIA driver's CUDA version is 12.2 which is older than the PTX compiler version 12.5.82. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "import jinns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09955058",
   "metadata": {},
   "source": [
    "Import other dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3abe5254-7556-424e-a57e-d364d67244a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import random, vmap\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "key = random.PRNGKey(2)\n",
    "key, subkey = random.split(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfbd766",
   "metadata": {},
   "source": [
    "Create the neural network architecture for the PINN with `equinox`. Note that we will use the same architecture for the 3 populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9396d007-04f1-4893-a3c8-c58c36845ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eqx_list = [\n",
    "    [eqx.nn.Linear, 1, 20],\n",
    "    [jax.nn.tanh],\n",
    "    [eqx.nn.Linear, 20, 20],\n",
    "    [jax.nn.tanh],\n",
    "    [eqx.nn.Linear, 20, 20],\n",
    "    [jax.nn.tanh],\n",
    "    [eqx.nn.Linear, 20, 1],\n",
    "    [jnp.exp]\n",
    "]\n",
    "key, subkey = random.split(key)\n",
    "u = jinns.utils.create_PINN(subkey, eqx_list, \"ODE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e47cbca-3af2-4ab2-a379-4b763c383843",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_nn_params = u.init_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d567b",
   "metadata": {},
   "source": [
    "Create a DataGenerator object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15088440",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 320\n",
    "batch_size = 32\n",
    "method = 'uniform'\n",
    "tmin = 0\n",
    "tmax = 1\n",
    "\n",
    "Tmax = 30\n",
    "key, subkey = random.split(key)\n",
    "train_data = jinns.data.DataGeneratorODE(\n",
    "    subkey,\n",
    "    n,\n",
    "    tmin,\n",
    "    tmax,\n",
    "    batch_size,\n",
    "    method=method\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1ac783",
   "metadata": {},
   "source": [
    "Initialize 3 set of neural network parameters for the 3 populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fec8c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_nn_params_list = []\n",
    "for _ in range(3):\n",
    "    key, subkey = random.split(key)\n",
    "    u = jinns.utils.create_PINN(subkey, eqx_list, \"ODE\", 0)\n",
    "    init_nn_params = u.init_params()\n",
    "    init_nn_params_list.append(init_nn_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b7faef",
   "metadata": {},
   "source": [
    "### Model parameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f6b6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial conditions for each species\n",
    "import numpy as onp\n",
    "N_0 = onp.array([10., 7., 4.])\n",
    "# growth rates for each species\n",
    "growth_rates = jnp.array([0.1, 0.5, 0.8])\n",
    "# carrying capacity for each species\n",
    "carrying_capacities = jnp.array([0.04, 0.02, 0.02])\n",
    "# interactions\n",
    "# NOTE that for the interaction between the species **with itself** is always at position 0\n",
    "# NOTE minus sign\n",
    "interactions = -jnp.array([[0, 0.001, 0.001], [0, 0.001, 0.001], [0, 0.001, 0.001]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a5ecb8",
   "metadata": {},
   "source": [
    "Then, we proceed to define the set of parameters as required by the losses' `equation(self, ...)` methods. This is a `jinns.paramaters.ParamDict` object, with two fields for\n",
    " 1. `nn_params`: the neural network parameters \n",
    " 2. `eq_params`: the equation parameters\n",
    "\n",
    "__Note__ that the keys of the sub dictionaries `nn_params` and `eq_params` (here `str(i)`) could differ !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7946039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = jinns.parameters.ParamsDict(\n",
    "    nn_params={str(i): init_nn_params_list[i] for i in range(3)},\n",
    "    eq_params={\n",
    "        str(i): {\n",
    "            \"carrying_capacity\": carrying_capacities[i],\n",
    "            \"growth_rate\": growth_rates[i],\n",
    "            \"interactions\": interactions[i, :],\n",
    "        }\n",
    "        for i in range(3)\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e595cbcd",
   "metadata": {},
   "source": [
    "Visualize the output of the neural networks with the random initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d18c73d2-ff23-4019-a7a1-40cc023dbf53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa0e471b0d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorized_u_init = vmap(lambda t: u(t, init_params.extract_params(\"0\")), (0), 0)\n",
    "vectorized_v_init = vmap(lambda t: u(t, init_params.extract_params(\"1\")), (0), 0)\n",
    "vectorized_w_init = vmap(lambda t: u(t, init_params.extract_params(\"2\")), (0), 0)\n",
    "\n",
    "\n",
    "plt.plot(train_data.times.sort(axis=0) * Tmax, vectorized_u_init(train_data.times.sort(axis=0)), label=\"N1\")\n",
    "plt.plot(train_data.times.sort(axis=0) * Tmax, vectorized_v_init(train_data.times.sort(axis=0)), label=\"N2\")\n",
    "plt.plot(train_data.times.sort(axis=0) * Tmax, vectorized_w_init(train_data.times.sort(axis=0)), label=\"N3\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7f24b",
   "metadata": {},
   "source": [
    "## Loss construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa14a602-1b0e-4582-876e-99d0322c57a0",
   "metadata": {},
   "source": [
    "We construct a SystemLossODE with GeneralizedLotkaVolterra losses for each population. Here `key_main` refer to the key in the dictionnary field `params.nn_params` which are the parameters for the main PINN of the equation (the PINN which represents the solution differentiated with respect to the `t`). In addition, `key_others` refer to the keys in `param.nn_params` which are the parameters for the PINNs interacting with `key_main`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6a65062",
   "metadata": {},
   "outputs": [],
   "source": [
    "N1_dynamic_loss = jinns.loss.GeneralizedLotkaVolterra(\n",
    "    key_main=\"0\", keys_other=[\"1\", \"2\"], Tmax=Tmax\n",
    ")\n",
    "N2_dynamic_loss = jinns.loss.GeneralizedLotkaVolterra(\n",
    "    key_main=\"1\", keys_other=[\"0\", \"2\"], Tmax=Tmax\n",
    ")\n",
    "N3_dynamic_loss = jinns.loss.GeneralizedLotkaVolterra(\n",
    "    key_main=\"2\", keys_other=[\"0\", \"1\"], Tmax=Tmax\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32b7477e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyTreeDef(CustomNode(PINN[('params',), ('slice_solution', 'eq_type', 'input_transform', 'output_transform', 'output_slice', 'static'), (slice(0, 1, None), 'ODE', <function create_PINN.<locals>.input_transform at 0x7fa0f4176e80>, <function create_PINN.<locals>.output_transform at 0x7fa0f4176f20>, None, _MLP(\n",
       "  layers=[\n",
       "    Linear(\n",
       "      weight=None,\n",
       "      bias=None,\n",
       "      in_features=1,\n",
       "      out_features=20,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    <wrapped function tanh>,\n",
       "    Linear(\n",
       "      weight=None,\n",
       "      bias=None,\n",
       "      in_features=20,\n",
       "      out_features=20,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    <wrapped function tanh>,\n",
       "    Linear(\n",
       "      weight=None,\n",
       "      bias=None,\n",
       "      in_features=20,\n",
       "      out_features=20,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    <wrapped function tanh>,\n",
       "    Linear(\n",
       "      weight=None,\n",
       "      bias=None,\n",
       "      in_features=20,\n",
       "      out_features=1,\n",
       "      use_bias=True\n",
       "    ),\n",
       "    <wrapped function exp>\n",
       "  ]\n",
       "))], [CustomNode(_MLP[('layers',), (), ()], [[CustomNode(Linear[('weight', 'bias'), ('in_features', 'out_features', 'use_bias'), (1, 20, True)], [*, *]), None, CustomNode(Linear[('weight', 'bias'), ('in_features', 'out_features', 'use_bias'), (20, 20, True)], [*, *]), None, CustomNode(Linear[('weight', 'bias'), ('in_features', 'out_features', 'use_bias'), (20, 20, True)], [*, *]), None, CustomNode(Linear[('weight', 'bias'), ('in_features', 'out_features', 'use_bias'), (20, 1, True)], [*, *]), None]])]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, treedef_u = jax.tree.flatten(u)\n",
    "treedef_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22b2647f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46183/3742859190.py:3: UserWarning: A JAX array is being set as static! This can result in unexpected behavior and is usually a mistake to do.\n",
      "  loss = jinns.loss.SystemLossODE(\n"
     ]
    }
   ],
   "source": [
    "loss_weights = jinns.loss.LossWeightsODEDict(dyn_loss=1, initial_condition=1 * Tmax)\n",
    "\n",
    "loss = jinns.loss.SystemLossODE(\n",
    "    u_dict={\"0\": u, \"1\": u, \"2\": u},\n",
    "    loss_weights=loss_weights,\n",
    "    dynamic_loss_dict={\n",
    "        \"0\": N1_dynamic_loss,\n",
    "        \"1\": N2_dynamic_loss,\n",
    "        \"2\": N3_dynamic_loss,\n",
    "    },\n",
    "    initial_condition_dict={\n",
    "        \"0\": (float(tmin), N_0[0]),\n",
    "        \"1\": (float(tmin), N_0[1]),\n",
    "        \"2\": (float(tmin), N_0[2]),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68b19a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': GeneralizedLotkaVolterra(\n",
       "   Tmax=30,\n",
       "   eq_params_heterogeneity=None,\n",
       "   key_main='0',\n",
       "   keys_other=['1', '2']\n",
       " ),\n",
       " '1': GeneralizedLotkaVolterra(\n",
       "   Tmax=30,\n",
       "   eq_params_heterogeneity=None,\n",
       "   key_main='1',\n",
       "   keys_other=['0', '2']\n",
       " ),\n",
       " '2': GeneralizedLotkaVolterra(\n",
       "   Tmax=30,\n",
       "   eq_params_heterogeneity=None,\n",
       "   key_main='2',\n",
       "   keys_other=['0', '1']\n",
       " )}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.dynamic_loss_dict\n",
    "# loss.derivative_keys_dyn_loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f5418d5-629f-4745-ad0f-3778020cc635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DerivativeKeysODE(\n",
      "  dyn_loss='nn_params',\n",
      "  observations=None,\n",
      "  initial_condition=None\n",
      ")\n",
      "nn_params 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'extract_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m train_data, batch \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mget_batch()\n\u001b[1;32m      4\u001b[0m losses_and_grad \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvalue_and_grad(loss\u001b[38;5;241m.\u001b[39mevaluate, \u001b[38;5;241m0\u001b[39m, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m losses, grads \u001b[38;5;241m=\u001b[39m \u001b[43mlosses_and_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m l_tot, d \u001b[38;5;241m=\u001b[39m losses\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml_tot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Recherche/INRAE/PINN/jinns/jinns/loss/_LossODE.py:526\u001b[0m, in \u001b[0;36mSystemLossODE.evaluate\u001b[0;34m(self, params_dict, batch)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28mprint\u001b[39m(params_dict_with_derivatives_at_loss_terms)\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dynamic_loss_apply(\n\u001b[1;32m    517\u001b[0m         dyn_loss\u001b[38;5;241m.\u001b[39mevaluate,\n\u001b[1;32m    518\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mu_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         u_type\u001b[38;5;241m=\u001b[39mPINN,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 526\u001b[0m dyn_loss_mse_dict \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdyn_loss_for_one_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamic_loss_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mderivative_keys_dyn_loss_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss_weights\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdyn_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mODE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# before when dynamic losses\u001b[39;49;00m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# where plain (unregister pytree) node classes, we could not traverse\u001b[39;49;00m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# this level. Now that dynamic losses are eqx.Module they can be\u001b[39;49;00m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# traversed by tree map recursion. Hence we need to specify to that\u001b[39;49;00m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we want to stop at this level\u001b[39;49;00m\n\u001b[1;32m    536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m mse_dyn_loss \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_reduce(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x, y: x \u001b[38;5;241m+\u001b[39m y, jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_leaves(dyn_loss_mse_dict)\n\u001b[1;32m    539\u001b[0m )\n\u001b[1;32m    541\u001b[0m \u001b[38;5;66;03m# initial conditions and observation_loss via the internal LossODE\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 24 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Recherche/INRAE/PINN/jinns/jinns/loss/_LossODE.py:516\u001b[0m, in \u001b[0;36mSystemLossODE.evaluate.<locals>.dyn_loss_for_one_key\u001b[0;34m(dyn_loss, derivative_key, loss_weight)\u001b[0m\n\u001b[1;32m    507\u001b[0m params_dict_with_derivatives_at_loss_terms \u001b[38;5;241m=\u001b[39m _set_derivatives(\n\u001b[1;32m    508\u001b[0m     params_dict,\n\u001b[1;32m    509\u001b[0m     DerivativeKeysODE(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m     ),\n\u001b[1;32m    514\u001b[0m )\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28mprint\u001b[39m(params_dict_with_derivatives_at_loss_terms)\n\u001b[0;32m--> 516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdynamic_loss_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdyn_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mu_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemporal_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams_dict_with_derivatives_at_loss_terms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdyn_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvmap_in_axes_t\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvmap_in_axes_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mu_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPINN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Recherche/INRAE/PINN/jinns/jinns/loss/_loss_utils.py:34\u001b[0m, in \u001b[0;36mdynamic_loss_apply\u001b[0;34m(dyn_loss, u, batches, params, vmap_axes, loss_weight, u_type)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m u_type \u001b[38;5;241m==\u001b[39m PINN \u001b[38;5;129;01mor\u001b[39;00m u_type \u001b[38;5;241m==\u001b[39m HYPERPINN \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(u, (PINN, HYPERPINN)):\n\u001b[1;32m     27\u001b[0m     v_dyn_loss \u001b[38;5;241m=\u001b[39m vmap(\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: dyn_loss(\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;241m*\u001b[39margs[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], u, args[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# we must place the params at the end\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     33\u001b[0m     )\n\u001b[0;32m---> 34\u001b[0m     residuals \u001b[38;5;241m=\u001b[39m \u001b[43mv_dyn_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     mse_dyn_loss \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mmean(jnp\u001b[38;5;241m.\u001b[39msum(loss_weight \u001b[38;5;241m*\u001b[39m residuals\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m u_type \u001b[38;5;241m==\u001b[39m SPINN \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(u, SPINN):\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Recherche/INRAE/PINN/jinns/jinns/loss/_loss_utils.py:28\u001b[0m, in \u001b[0;36mdynamic_loss_apply.<locals>.<lambda>\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03mSometimes when u is a lambda function a or dict we do not have access to\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03mits type here, hence the last argument\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m u_type \u001b[38;5;241m==\u001b[39m PINN \u001b[38;5;129;01mor\u001b[39;00m u_type \u001b[38;5;241m==\u001b[39m HYPERPINN \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(u, (PINN, HYPERPINN)):\n\u001b[1;32m     27\u001b[0m     v_dyn_loss \u001b[38;5;241m=\u001b[39m vmap(\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs: \u001b[43mdyn_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# we must place the params at the end\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     31\u001b[0m         vmap_axes,\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     33\u001b[0m     )\n\u001b[1;32m     34\u001b[0m     residuals \u001b[38;5;241m=\u001b[39m v_dyn_loss(\u001b[38;5;241m*\u001b[39mbatches, params)\n\u001b[1;32m     35\u001b[0m     mse_dyn_loss \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mmean(jnp\u001b[38;5;241m.\u001b[39msum(loss_weight \u001b[38;5;241m*\u001b[39m residuals\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Recherche/INRAE/PINN/jinns/jinns/loss/_DynamicLossAbstract.py:183\u001b[0m, in \u001b[0;36mODE.evaluate\u001b[0;34m(self, t, u, params)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    178\u001b[0m     t: Float[Array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    179\u001b[0m     u: eqx\u001b[38;5;241m.\u001b[39mModule \u001b[38;5;241m|\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, eqx\u001b[38;5;241m.\u001b[39mModule],\n\u001b[1;32m    180\u001b[0m     params: Params \u001b[38;5;241m|\u001b[39m ParamsDict,\n\u001b[1;32m    181\u001b[0m ):\n\u001b[1;32m    182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Here we call DynamicLoss._evaluate with x=None\"\"\"\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Recherche/INRAE/PINN/jinns/jinns/loss/_DynamicLossAbstract.py:133\u001b[0m, in \u001b[0;36mDynamicLoss._evaluate\u001b[0;34m(self, t, x, u, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, t, x, u, params):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# Here we handle the various possible signature\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eq_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mODE\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 133\u001b[0m         ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eq_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatio PDE\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    135\u001b[0m         ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mequation(x, u, params)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Recherche/INRAE/PINN/jinns/jinns/loss/_DynamicLoss.py:155\u001b[0m, in \u001b[0;36mGeneralizedLotkaVolterra.equation\u001b[0;34m(self, t, u_dict, params_dict)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03mEvaluate the dynamic loss at `t`.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03mFor stability we implement the dynamic loss in log space.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m    top level are \"nn_params\" and \"eq_params\"\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mprint\u001b[39m(params_dict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_main)\n\u001b[0;32m--> 155\u001b[0m params_main \u001b[38;5;241m=\u001b[39m \u001b[43mparams_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_params\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_main)\n\u001b[1;32m    157\u001b[0m u \u001b[38;5;241m=\u001b[39m u_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_main]\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# need to index with [0] since u output is nec (1,)\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'extract_params'"
     ]
    }
   ],
   "source": [
    "# Testing the loss function\n",
    "train_data, batch = train_data.get_batch()\n",
    "\n",
    "losses_and_grad = jax.value_and_grad(loss.evaluate, 0, has_aux=True)\n",
    "losses, grads = losses_and_grad(\n",
    "    init_params,\n",
    "    batch\n",
    ")\n",
    "l_tot, d = losses\n",
    "print(f\"total loss: {l_tot}\")\n",
    "print(f\"Individual losses: { {key: f'{val:.2f}' for key, val in d.items()} }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64835b79-0bce-4f06-bd57-5ee051796663",
   "metadata": {},
   "source": [
    "## Learning the neural network parameters\n",
    "The learning process here consider known equation parameters `eq_params`. We thus only update `nn_params`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e2c75a4-e3de-4d10-9424-4ee4ae206da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = init_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d0106ad-d1e4-4fa8-958d-c8ebd4572d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "import optax\n",
    "tx = optax.adam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "055a7e63-4d0e-4246-b792-2007a0deeaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = int(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9284d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = random.split(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df0ab21d-bfc1-4e81-8708-df8b30d0173b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Value '0' with type <class 'str'> is not a valid JAX type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m params, total_loss_list, loss_by_term_dict, data, loss, _, _ , _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mjinns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Recherche/INRAE/PINN/jinns/jinns/solver/_solve.py:360\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(n_iter, init_params, data, loss, optimizer, print_loss_every, opt_state, tracked_params_key_list, param_data, obs_data, validation, obs_batch_sharding, verbose)\u001b[0m\n\u001b[1;32m    358\u001b[0m     break_fun \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mjit(break_fun)\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# print(f\"{break_fun(carry)=}\")\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m     carry \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbreak_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_iteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcarry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m (\n\u001b[1;32m    363\u001b[0m     i,\n\u001b[1;32m    364\u001b[0m     loss,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    371\u001b[0m     validation_crit_values,\n\u001b[1;32m    372\u001b[0m ) \u001b[38;5;241m=\u001b[39m carry\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "    \u001b[0;31m[... skipping hidden 5 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/pinn-gpu/lib/python3.11/site-packages/jax/_src/core.py:1518\u001b[0m, in \u001b[0;36mconcrete_aval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__jax_array__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1517\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete_aval(x\u001b[38;5;241m.\u001b[39m__jax_array__())\n\u001b[0;32m-> 1518\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid JAX \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1519\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Value '0' with type <class 'str'> is not a valid JAX type"
     ]
    }
   ],
   "source": [
    "params, total_loss_list, loss_by_term_dict, data, loss, _, _ , _, _ = jinns.solve(\n",
    "    init_params=params,\n",
    "    data=train_data,\n",
    "    optimizer=tx,\n",
    "    loss=loss,\n",
    "    n_iter=n_iter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b65dfc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(4555.6255, dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0066b072",
   "metadata": {},
   "source": [
    "# TO DELETE : test modif loss + solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2749d465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39351/605340911.py:1: UserWarning: A JAX array is being set as static! This can result in unexpected behavior and is usually a mistake to do.\n",
      "  loss2 = jinns.loss.SystemLossODE(\n"
     ]
    }
   ],
   "source": [
    "loss2 = jinns.loss.SystemLossODE(\n",
    "    u_dict={\"0\": u, \"1\": u, \"2\": u},\n",
    "    loss_weights=loss_weights,\n",
    "    dynamic_loss_dict={\n",
    "        \"0\": N1_dynamic_loss,\n",
    "        \"1\": N2_dynamic_loss,\n",
    "        \"2\": N3_dynamic_loss,\n",
    "    },\n",
    "    initial_condition_dict={\n",
    "        \"0\": (float(tmin), N_0[0]),\n",
    "        \"1\": (float(tmin), N_0[1]),\n",
    "        \"2\": (float(tmin), N_0[2]),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "deadbe6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree.structure(loss) == jax.tree.structure(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b952ec54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jax.tree.leaves(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4a3fc40",
   "metadata": {},
   "outputs": [
    {
     "ename": "TracerBoolConversionError",
     "evalue": "Attempted boolean conversion of traced array with shape bool[].\nThe error occurred while tracing the function break_fun at /home/nicolas/Recherche/INRAE/PINN/jinns/jinns/solver/_solve.py:489 for while_cond. This value became a tracer due to JAX operations on these lines:\n\n  operation a\u001b[35m:bool[20,1]\u001b[39m = eq b b\n    from line <string>:4:10 (__create_fn__.<locals>.__eq__)\n\n  operation a\u001b[35m:bool[]\u001b[39m = and b c\n    from line <string>:4:10 (__create_fn__.<locals>.__eq__)\n\n  operation a\u001b[35m:bool[20]\u001b[39m = eq b b\n    from line <string>:4:10 (__create_fn__.<locals>.__eq__)\n\n  operation a\u001b[35m:bool[20,20]\u001b[39m = eq b b\n    from line <string>:4:10 (__create_fn__.<locals>.__eq__)\n\n  operation a\u001b[35m:bool[20]\u001b[39m = eq b b\n    from line <string>:4:10 (__create_fn__.<locals>.__eq__)\n\n(Additional originating lines are not shown.)\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTracerBoolConversionError\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m temp \u001b[38;5;241m=\u001b[39m \u001b[43mjinns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Recherche/INRAE/PINN/jinns/jinns/solver/_solve.py:360\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(n_iter, init_params, data, loss, optimizer, print_loss_every, opt_state, tracked_params_key_list, param_data, obs_data, validation, obs_batch_sharding, verbose)\u001b[0m\n\u001b[1;32m    358\u001b[0m     break_fun \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mjit(break_fun)\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# print(f\"{break_fun(carry)=}\")\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m     carry \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbreak_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_iteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcarry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m (\n\u001b[1;32m    363\u001b[0m     i,\n\u001b[1;32m    364\u001b[0m     loss,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    371\u001b[0m     validation_crit_values,\n\u001b[1;32m    372\u001b[0m ) \u001b[38;5;241m=\u001b[39m carry\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "    \u001b[0;31m[... skipping hidden 15 frame]\u001b[0m\n",
      "File \u001b[0;32m<string>:4\u001b[0m, in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/pinn-gpu/lib/python3.11/site-packages/jax/_src/core.py:1538\u001b[0m, in \u001b[0;36mconcretization_function_error.<locals>.error\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg):\n\u001b[0;32m-> 1538\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m TracerBoolConversionError(arg)\n",
      "\u001b[0;31mTracerBoolConversionError\u001b[0m: Attempted boolean conversion of traced array with shape bool[].\nThe error occurred while tracing the function break_fun at /home/nicolas/Recherche/INRAE/PINN/jinns/jinns/solver/_solve.py:489 for while_cond. This value became a tracer due to JAX operations on these lines:\n\n  operation a\u001b[35m:bool[20,1]\u001b[39m = eq b b\n    from line <string>:4:10 (__create_fn__.<locals>.__eq__)\n\n  operation a\u001b[35m:bool[]\u001b[39m = and b c\n    from line <string>:4:10 (__create_fn__.<locals>.__eq__)\n\n  operation a\u001b[35m:bool[20]\u001b[39m = eq b b\n    from line <string>:4:10 (__create_fn__.<locals>.__eq__)\n\n  operation a\u001b[35m:bool[20,20]\u001b[39m = eq b b\n    from line <string>:4:10 (__create_fn__.<locals>.__eq__)\n\n  operation a\u001b[35m:bool[20]\u001b[39m = eq b b\n    from line <string>:4:10 (__create_fn__.<locals>.__eq__)\n\n(Additional originating lines are not shown.)\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError"
     ]
    }
   ],
   "source": [
    "temp = jinns.solve(\n",
    "    init_params=params,\n",
    "    data=train_data,\n",
    "    optimizer=tx,\n",
    "    loss=loss2,\n",
    "    n_iter=n_iter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a1757",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c794ff",
   "metadata": {},
   "source": [
    "Plot the loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd778b4-d9d9-4f69-ad02-2a3f7eacf59d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for loss_name, loss_values in loss_by_term_dict.items():\n",
    "    plt.plot(jnp.log10(loss_values), label=loss_name)\n",
    "plt.plot(jnp.log10(total_loss_list), label=\"total loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6247171",
   "metadata": {},
   "source": [
    "Plot the ODE solutions learned by the PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d473743-c9a8-4406-b18c-256496cfde59",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_est_fp = vmap(lambda t:u(t, params.extract_params(\"0\")), (0), 0)\n",
    "v_est_fp = vmap(lambda t:u(t, params.extract_params(\"1\")), (0), 0)\n",
    "w_est_fp = vmap(lambda t:u(t, params.extract_params(\"2\")), (0), 0)\n",
    "\n",
    "\n",
    "key, subkey = random.split(key, 2)\n",
    "val_data = jinns.data.DataGeneratorODE(subkey, n, tmin, tmax, batch_size, method)\n",
    "\n",
    "import pandas as pd\n",
    "ts = val_data.times.sort(axis=0)\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"t\": ts * Tmax, # rescale time for plotting\n",
    "        \"N1\": u_est_fp(ts).squeeze(),\n",
    "        \"N2\": v_est_fp(ts).squeeze(),\n",
    "        \"N3\": w_est_fp(ts).squeeze(),\n",
    "        \"Method\": \"PINN\"\n",
    "    },\n",
    ")\n",
    "df.plot(x=\"t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed49c41",
   "metadata": {},
   "source": [
    "## Compare with the scipy solver\n",
    "Code from Lorenzo Sala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "484380a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "# NOTE the following line is not accurate as it skips one batch\n",
    "\n",
    "def lotka_volterra_log(y_log, t, eq_params):\n",
    "    \"\"\"\n",
    "    Generalized Lotka-Volterra model for N bacterial species, with logarithmic transformation for stability.\n",
    "\n",
    "    Parameters:\n",
    "        y_log (array): Array of log-transformed bacterial populations.\n",
    "        t (float): Time.\n",
    "        params (tuple): Tuple of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        dydt (array): Array of derivative of log-transformed bacterial populations with respect to time.\n",
    "    \"\"\"\n",
    "    alpha, beta, gamma, _ = eq_params\n",
    "    N = len(y_log)\n",
    "    y = np.exp(y_log)\n",
    "    dydt = np.zeros(N)\n",
    "\n",
    "    for i in range(N):\n",
    "        dydt[i] = y[i] * (alpha[i] - beta[i] * np.sum(y) - np.sum([gamma[j][i] * y[j] for j in range(N)]))\n",
    "\n",
    "    dydt_log = dydt / y\n",
    "\n",
    "    return dydt_log\n",
    "\n",
    "# Define name bacteria\n",
    "names = ['N1', 'N2', 'N3']\n",
    "N = len(names)\n",
    "\n",
    "# Define model parameters\n",
    "death_rates = None\n",
    "eq_params = (growth_rates, carrying_capacities, interactions, death_rates)\n",
    "\n",
    "# Define initial bacterial populations\n",
    "y0 = [10, 7, 4] #[0.26, 0.37, 0.57] #\n",
    "\n",
    "# Define time points\n",
    "Tmax = 30\n",
    "t = ts * Tmax\n",
    "\n",
    "############################\n",
    "\n",
    "y0_log = np.log(y0)\n",
    "y_log = odeint(lotka_volterra_log, y0_log, t, args=(eq_params,))\n",
    "y = np.exp(y_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69d5f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparative plots\n",
    "df_scipy = pd.DataFrame(\n",
    "    {\n",
    "        \"t\": ts * Tmax, # rescale time for plotting\n",
    "        \"Method\": \"Scipy solver\"\n",
    "    } |\n",
    "    {\n",
    "        f\"N{i+1}\": y[:,i] for i in range(3)\n",
    "    },\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d66b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df_plot = pd.concat((df, df_scipy)).melt(id_vars=['Method', \"t\"], var_name=\"Population\", value_name=\"Solution\")\n",
    "sns.relplot(df_plot, kind='line', x='t', y='Solution', hue='Population',  style='Method', height=4, aspect=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e962c046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "991718e94fb5d91fa62c7598521d2199c208ff1ff700f1ac060f334be0bee194"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
